{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spam_data in dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_path=\"spambase/spambase.data\"\n",
    "email_data=pd.read_csv(file_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "#calculating the mean of all features\n",
    "data_features=email_data.iloc[:,0:57]\n",
    "mean_data=data_features.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarizing data\n",
    "for index in range(0,len(email_data)): \n",
    "    for col in range(0,57):\n",
    "        if email_data.iat[index,col] > mean_data[col]:\n",
    "            email_data.iat[index,col]=1\n",
    "        else:\n",
    "            email_data.iat[index,col]=0\n",
    "\n",
    "binary_data=email_data.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide data set into training and testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(binary_data, train_size=0.60,random_state=31)\n",
    "notspam_set, spam_set = [x for _, x in train_data.groupby(train_data[57] == 1)]\n",
    "testing_data=pd.concat([test_data, notspam_set], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check and update hpothesis\n",
    "def computehyp( h1,x1 ):\n",
    "    for col in range(len(h1)):\n",
    "        if x1[col] != h1[col]: \n",
    "            h1[col]=\"?\"\n",
    "        else:\n",
    "            pass\n",
    "                           \n",
    "\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm implementation\n",
    "x=spam_set.iloc[0,0:57]\n",
    "h=x\n",
    "i=1\n",
    "while i < (len(spam_set)):\n",
    "    x=spam_set.iloc[i,0:57]\n",
    "    h=computehyp(h,x)\n",
    "    i=i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing model on test data\n",
    "lis=[]\n",
    "co=0\n",
    "inco=0\n",
    "X_test=test_data.iloc[:,0:57]\n",
    "Y_test=test_data.iloc[:,-1]\n",
    "j=0\n",
    "for i in range(0,len(X_test)):\n",
    "    tmp=X_test.iloc[i,:]\n",
    "    co=0\n",
    "    inco=0\n",
    "    #print(*tmp)\n",
    "    #print(*h)\n",
    "    for index in range(0,len(h)):\n",
    "        if tmp[index]==h[index]:\n",
    "            co=co+1\n",
    "        else:\n",
    "            inco=inco+1\n",
    "    if co==1:\n",
    "        lis.append(1)\n",
    "    else:\n",
    "        lis.append(0)\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correctly predicted emails 939\n",
      "Number of incorrectly predicted emails 902\n",
      "Average 51.0048886474742\n"
     ]
    }
   ],
   "source": [
    "# Checking predicted and actual lables and finding accuracy\n",
    "cor_pred=0\n",
    "incor_pred=0\n",
    "arr=[]\n",
    "for i in range (0,len(Y_test)):\n",
    "    a=Y_test.iat[i]\n",
    "    arr.append(a)\n",
    "    \n",
    "for index in range(0,len(arr)):\n",
    "    if arr[index]==lis[index]:\n",
    "        cor_pred=cor_pred+1\n",
    "    else:\n",
    "        incor_pred=incor_pred+1\n",
    "print(\"Number of correctly predicted emails\",cor_pred)\n",
    "print(\"Number of incorrectly predicted emails\",incor_pred)\n",
    "av=(cor_pred/(len(Y_test)))*100\n",
    "print(\"Average\",av)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
